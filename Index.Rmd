---
title: "Index"
author: "Lucas Finner"
date: "7/14/2020"
output: index
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(include = FALSE)
library(tidyverse)
library(kableExtra)
library(HelpersMG)
library(readr)
library(knitr)
```
This is the library needed for R markdown. All of the resources used come from this library.

```{r Load_data_set_1}
average <- read_csv("raw_data/WHO-COVID-19-global-data.csv")
average <- filter(average, Country == "United States of America")
a <- ggplot(average,aes(x=Date_reported,y=Cumulative_cases, group_by(Country))) + geom_line(show.legend = TRUE) +theme(legend.position = "bottom") + labs(title = "Cumulative cases in the United States") + geom_smooth(method = "lm", se=FALSE, color="blue", formula = y ~ x)

print(a)

ggsave("sup", plot = a,device = "jpeg", path = "output")
```
This chunk takes raw data from OurWorldInData and imports it to crate a graph. the data imported is for all countries, but for our purposes we are filtering just for the United States. A ggpot is then created with the x-axis, y-axis, graph line, corresponding linear line, and labels. This will be sufficient to include in our report later on. The graph is then saved into our "output" folder that will make it easier to utilize in other documents.


```{r Load_data_set_2}
CityAverage <- read_tsv("raw_data/us_metro_confirmed_cases_cdl.tsv")
CityAverage <- filter(CityAverage, Metropolitan == "New York-Northern NJ-Long Is NY-NJ-PA")
CityAverage <- pivot_longer(CityAverage, -Metropolitan, names_to = "Date", values_to = "Cumulative Cases")
CityAverage <- CityAverage[185:200,]

print(CityAverage)

write.table(CityAverage, file = "output/New York Cumulative Cases")
```

```{r Load_data_set_3}
CityAverage <- read_tsv("raw_data/us_metro_confirmed_cases_cdl.tsv")
CityAverage <- filter(CityAverage, Metropolitan == "Chicago-Joliet-Naperville IL-IN-WI")
CityAverage <- pivot_longer(CityAverage, -Metropolitan, names_to = "Date", values_to = "Cumulative Cases")
CityAverage <- CityAverage[185:200,]

print(CityAverage)
write.table(CityAverage, file = "output/Chicago Cumulative Cases")
```
Load_data_set_2 and Load_data_set_3 both function in similar ways. Data for both is imported from the Harvard Dataverse. From there, each chunk is filtered to the specific urban Area we are trying to retrieve data from (Chicago and New York). The data is then pivoted to inverse the rows and columns. This is done to better interpret the data by date rather than by city. From there a sample of the data is taken to visualize. This is done to highlight the most important dates and to not show an overwhelming number of rows in the table. In this instance July was used because of its recency. The last item perfromed in these chunks is the table is written into a file in the output folder. From there it can be used for other purposes. 